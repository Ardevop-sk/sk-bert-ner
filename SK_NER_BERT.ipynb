{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER BERT TPU",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ardevop-sk/sk-bert-ner/blob/master/SK_NER_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2XB_l-Hgzq_",
        "colab_type": "text"
      },
      "source": [
        "# Training BERT for Named Entity Recognition in Slovak language"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZPgpRl5g2e2",
        "colab_type": "text"
      },
      "source": [
        "In this experiment, we will be training a state-of-the-art Natural Language Understanding model [BERT](https://arxiv.org/abs/1810.04805.) on manually annotated korpus of Court decisions from https://ru.justice.sk/ data using Google Cloud infrastructure.\n",
        "\n",
        "This guide covers all stages of the procedure, including:\n",
        "\n",
        "1. Setting up the training environment\n",
        "2. Getting the data\n",
        "3. Preparing models\n",
        "4. Training model on cloud GPU\n",
        "5. Downloading model to GCS\n",
        "6. Serving BERT model for NER\n",
        "7. Testing the services\n",
        "\n",
        "For persistent storage of training data and model, you will require a Google Cloud Storage bucket. \n",
        "Please follow the [Google Cloud TPU quickstart](https://cloud.google.com/tpu/docs/quickstart) to create a GCP account and GCS bucket. New Google Cloud users have [$300 free credit](https://cloud.google.com/free/) to get started with any GCP product.\n",
        "This document is based on document from: https://towardsdatascience.com/pre-training-bert-from-scratch-with-cloud-tpu-6e2f71028379"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODimOhBR05yR",
        "colab_type": "text"
      },
      "source": [
        "MIT License\n",
        "\n",
        "Copyright (c) [2020] [Filip Bednárik]\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjad5jsr9YaM",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: setting up training environment\n",
        "You will need to set the Runtime -> Change runtime type to GPU.\n",
        "\n",
        "We need to install BERT and download python scripts for training.\n",
        "The Jupyter environment allows executing bash commands directly from the notebook by using an exclamation mark ‘!’. We will be exploiting this approach to make use of several other bash commands throughout the experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvfNt0mVZ33n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bert-tensorflow\n",
        "!git clone https://github.com/Ardevop-sk/BERT-NER.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-6fBVe0DuA9",
        "colab_type": "text"
      },
      "source": [
        "We need to authenticate with google to use GCS later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S4CiOh3RzFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import nltk\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "\n",
        "from glob import glob\n",
        "from google.colab import auth, drive\n",
        "from tensorflow.keras.utils import Progbar\n",
        "\n",
        "auth.authenticate_user()\n",
        "  \n",
        "# configure logging\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "# create formatter and add it to the handlers\n",
        "formatter = logging.Formatter('%(asctime)s :  %(message)s')\n",
        "sh = logging.StreamHandler()\n",
        "sh.setLevel(logging.INFO)\n",
        "sh.setFormatter(formatter)\n",
        "log.handlers = [sh]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI0STeRRG6ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  log.info(\"Using TPU runtime\")\n",
        "  USE_TPU = True\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    log.info('TPU address is ' + TPU_ADDRESS)\n",
        "    # Upload credentials to TPU.\n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    \n",
        "else:\n",
        "  log.warning('Not connected to TPU runtime')\n",
        "  USE_TPU = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGVXMoC-aMy1",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Getting the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnvZvzmdDz3G",
        "colab_type": "text"
      },
      "source": [
        "We either upload or crawl and transform data to following format:\n",
        "\n",
        "```\n",
        "My O\n",
        "name O\n",
        "is O\n",
        "Filip I-PERSON\n",
        ". O\n",
        "\n",
        "This O\n",
        "is O\n",
        "second O\n",
        "sentence O\n",
        ". O\n",
        "```\n",
        "\n",
        "Note that code accepts input divided by space \" \" or tab \"\\t\". Note: You don't need to filter columns if your corpus has more columns divided by space or tab. The only condition is that the first column is input token and last column is the NER label.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1jA-WlcFAcE",
        "colab_type": "text"
      },
      "source": [
        "### 2.1a Uploading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2cEdwjNeJZO",
        "colab_type": "text"
      },
      "source": [
        "For now, you will need to ask [me](https://www.linkedin.com/in/filipbednarik/) for the manually annotated dataset and handle the personal data contained according to actual legislations. Or use your own dataset in above mentioned format. I am working on fully automated solution using crawler and delegating the GDPR problem to you :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FotFkkshbdvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -la\n",
        "!cd BERT-NER/data\n",
        "from google.colab import files\n",
        "uploadedTrain = files.upload()\n",
        "uploadedDev = files.upload()\n",
        "uploadedTest = files.upload()\n",
        "!ls -la"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjg8TruFFQmx",
        "colab_type": "text"
      },
      "source": [
        "### 2.1b Crawl and transform the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSrrCg6vFYLb",
        "colab_type": "text"
      },
      "source": [
        "TBD Crawler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6CltOIKFkSf",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Copy data to the right place"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZWaWm-FFJti",
        "colab_type": "text"
      },
      "source": [
        "Finally We copy it to the right place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CUCvWbmcVVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv -f train.txt BERT-NER/data/train.txt\n",
        "!mv -f dev.txt BERT-NER/data/dev.txt\n",
        "!mv -f test.txt BERT-NER/data/test.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhHr2PRbFslM",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Preparing models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLdbAlUpF7hz",
        "colab_type": "text"
      },
      "source": [
        "We either download official Bert model trained on Wikipedia for multiple languages, or use our own pre-trained model (for example pre-trained on Slovak Opensubtitles https://towardsdatascience.com/pre-training-bert-from-scratch-with-cloud-tpu-6e2f71028379)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB27C2zGai63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CJvCNmOcjlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip multi_cased_L-12_H-768_A-12.zip -d BERT-NER/\n",
        "!ls -la BERT-NER/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRQd4-v0nQqH",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Training model on cloud GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhEBiZrvGjBR",
        "colab_type": "text"
      },
      "source": [
        "Training may take more than half and hour. Depending on your dataset and currently available GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCi2oSdInRkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python BERT-NER/BERT_NER.py \\\n",
        " --task_name=\"NER\" \\\n",
        " --do_lower_case=False \\\n",
        " --crf=False \\\n",
        " --do_train=True \\\n",
        " --do_eval=True \\\n",
        " --do_predict=True \\\n",
        " --data_dir=BERT-NER/data \\\n",
        " --middle_output=BERT-NER/middle_data \\\n",
        " --vocab_file=BERT-NER/multi_cased_L-12_H-768_A-12/vocab.txt \\\n",
        " --bert_config_file=BERT-NER/multi_cased_L-12_H-768_A-12/bert_config.json \\\n",
        " --init_checkpoint=BERT-NER/multi_cased_L-12_H-768_A-12/bert_model.ckpt \\\n",
        " --max_seq_length=128 \\\n",
        " --train_batch_size=32 \\\n",
        " --learning_rate=2e-5 \\\n",
        " --num_train_epochs=3.0 \\\n",
        " --output_dir=BERT-NER/output/result_dir \\\n",
        " --labels=\"[PAD],O,Sud,Osoba,Adresa,Organizacia,ICO,Narodenie,X,[CLS],[SEP]\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqdLXhL4Gun5",
        "colab_type": "text"
      },
      "source": [
        "Alternatively you can train on TPU if you fancy TPU. You would need to configure it with GCS though."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SODUgwfMipPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python BERT-NER/BERT_NER.py \\\n",
        " --task_name=\"NER\" \\\n",
        " --do_lower_case=False \\\n",
        " --crf=False \\\n",
        " --do_train=True \\\n",
        " --do_eval=True \\\n",
        " --do_predict=True \\\n",
        " --data_dir=BERT-NER/data \\\n",
        " --middle_output=BERT-NER/middle_data \\\n",
        " --vocab_file=BERT-NER/multi_cased_L-12_H-768_A-12/vocab.txt \\\n",
        " --bert_config_file=BERT-NER/multi_cased_L-12_H-768_A-12/bert_config.json \\\n",
        " --init_checkpoint=BERT-NER/multi_cased_L-12_H-768_A-12/bert_model.ckpt \\\n",
        " --max_seq_length=128 \\\n",
        " --train_batch_size=32 \\\n",
        " --learning_rate=2e-5 \\\n",
        " --num_train_epochs=3.0 \\\n",
        " --output_dir=BERT-NER/output/result_dir \\\n",
        " --use_tpu=True \\\n",
        " --tpu_name=grpc://10.110.157.90:8470"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYtwtDnesaQQ",
        "colab_type": "text"
      },
      "source": [
        "We will check the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gngtEZWqVhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -la BERT-NER/output/result_dir\n",
        "!ls -la BERT-NER/output/result_dir/eval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxrlIaMLHvOC",
        "colab_type": "text"
      },
      "source": [
        "We will evaluate the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIw2fY_zHxYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TBD eval results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42W8gCm9HJGi",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Downloading model to GCS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDtrt68QQIHs",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "BUCKET_NAME = \"ardevop-sk-bert-sk\" #@param {type:\"string\"}\n",
        "MODEL_DIR = \"model_ner\" #@param {type:\"string\"}\n",
        "SRC_DIR = \"BERT-NER/output/result_dir\" #@param {type:\"string\"}\n",
        "tf.gfile.MkDir(MODEL_DIR)\n",
        "\n",
        "if not BUCKET_NAME:\n",
        "  log.warning(\"WARNING: BUCKET_NAME is not set. \"\n",
        "              \"You will not be able to train the model.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txgrEDugRG48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if BUCKET_NAME:\n",
        "  !gsutil cp -r $SRC_DIR gs://$BUCKET_NAME/$MODEL_DIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-DdbjZnHUmP",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: Serving BERT model for NER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdEM8pq3HZ-b",
        "colab_type": "text"
      },
      "source": [
        "TBD: https://github.com/Ardevop-sk/bert-as-service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u17_Xk2KHnfH",
        "colab_type": "text"
      },
      "source": [
        "## Step 7: Testing the services"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc_x8s2NH0yQ",
        "colab_type": "text"
      },
      "source": [
        "TBD: Swagger UI"
      ]
    }
  ]
}